{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13170,"status":"ok","timestamp":1688940295305,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"C19qic_Hygck","outputId":"f06911d9-e71f-498b-a7ad-cbcc24924d28"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1688940295305,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"bXUyIi4x3gMY","outputId":"425b18f9-5fe5-4247-a2f0-122a2971ae6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/Shareddrives/Anomaly\n"]}],"source":["%cd /content/gdrive/Shareddrives/Anomaly/"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":502,"status":"ok","timestamp":1688940295805,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"5ED6MSGv4AvS"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":399,"status":"ok","timestamp":1688940296200,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"KCl7zIeXLI0H"},"outputs":[],"source":["far_df = pd.read_csv('/content/gdrive/Shareddrives/Anomaly/dataset/df_kae_far_nsl_kdd_5k_2k.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1688940296201,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"QzkfKQvmLc9d","outputId":"e76caa68-835b-43e5-cb66-571633f0b0cc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          2      0.00    0.00.1    0.00.2    0.00.3      1.00    0.00.4  \\\n","0  0.339641  1.602655  1.605095 -0.374364 -0.374433 -1.389660  0.038526   \n","1  0.322176 -0.637213 -0.631933  2.746390  2.715352 -1.139445 -0.016932   \n","2  0.715160  1.602655  1.605095 -0.374364 -0.374433 -1.389660 -0.016932   \n","3  0.287244  1.602655  1.605095 -0.374364 -0.374433 -1.184939 -0.016932   \n","4  1.623390  1.602655  1.605095 -0.374364 -0.374433 -1.298673 -0.072391   \n","\n","     0.00.5       150        25    0.17.1      0.03    0.17.2    0.00.6  \\\n","0 -0.374561  0.734337 -0.809862 -0.938292 -0.174419 -0.480194 -0.289105   \n","1 -0.374561  0.734337 -0.873095 -1.005115 -0.068555 -0.480194 -0.289105   \n","2 -0.374561  0.734337 -0.963427 -1.071937 -0.174419 -0.480194 -0.289105   \n","3 -0.374561  0.734337 -0.909228 -1.027389 -0.068555 -0.480194 -0.289105   \n","4 -0.374561  0.734337 -0.836962 -0.960566 -0.174419 -0.480194 -0.289105   \n","\n","     0.00.7    0.00.8      0.05    0.00.9        20  Anomaly Flag  \n","0  1.608750  1.618946 -0.387635 -0.376389 -0.219968           0.0  \n","1 -0.639535 -0.624874  2.874397  2.753901  0.652822           0.0  \n","2  1.608750  1.618946 -0.387635 -0.376389  0.652822           0.0  \n","3  1.608750  1.618946 -0.387635 -0.376389  0.652822           0.0  \n","4  1.608750  1.618946 -0.387635 -0.376389  0.652822           0.0  "],"text/html":["\n","  <div id=\"df-ae705f42-c801-4a00-a9fd-fb67d820f0ce\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>0.00</th>\n","      <th>0.00.1</th>\n","      <th>0.00.2</th>\n","      <th>0.00.3</th>\n","      <th>1.00</th>\n","      <th>0.00.4</th>\n","      <th>0.00.5</th>\n","      <th>150</th>\n","      <th>25</th>\n","      <th>0.17.1</th>\n","      <th>0.03</th>\n","      <th>0.17.2</th>\n","      <th>0.00.6</th>\n","      <th>0.00.7</th>\n","      <th>0.00.8</th>\n","      <th>0.05</th>\n","      <th>0.00.9</th>\n","      <th>20</th>\n","      <th>Anomaly Flag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.339641</td>\n","      <td>1.602655</td>\n","      <td>1.605095</td>\n","      <td>-0.374364</td>\n","      <td>-0.374433</td>\n","      <td>-1.389660</td>\n","      <td>0.038526</td>\n","      <td>-0.374561</td>\n","      <td>0.734337</td>\n","      <td>-0.809862</td>\n","      <td>-0.938292</td>\n","      <td>-0.174419</td>\n","      <td>-0.480194</td>\n","      <td>-0.289105</td>\n","      <td>1.608750</td>\n","      <td>1.618946</td>\n","      <td>-0.387635</td>\n","      <td>-0.376389</td>\n","      <td>-0.219968</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.322176</td>\n","      <td>-0.637213</td>\n","      <td>-0.631933</td>\n","      <td>2.746390</td>\n","      <td>2.715352</td>\n","      <td>-1.139445</td>\n","      <td>-0.016932</td>\n","      <td>-0.374561</td>\n","      <td>0.734337</td>\n","      <td>-0.873095</td>\n","      <td>-1.005115</td>\n","      <td>-0.068555</td>\n","      <td>-0.480194</td>\n","      <td>-0.289105</td>\n","      <td>-0.639535</td>\n","      <td>-0.624874</td>\n","      <td>2.874397</td>\n","      <td>2.753901</td>\n","      <td>0.652822</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.715160</td>\n","      <td>1.602655</td>\n","      <td>1.605095</td>\n","      <td>-0.374364</td>\n","      <td>-0.374433</td>\n","      <td>-1.389660</td>\n","      <td>-0.016932</td>\n","      <td>-0.374561</td>\n","      <td>0.734337</td>\n","      <td>-0.963427</td>\n","      <td>-1.071937</td>\n","      <td>-0.174419</td>\n","      <td>-0.480194</td>\n","      <td>-0.289105</td>\n","      <td>1.608750</td>\n","      <td>1.618946</td>\n","      <td>-0.387635</td>\n","      <td>-0.376389</td>\n","      <td>0.652822</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.287244</td>\n","      <td>1.602655</td>\n","      <td>1.605095</td>\n","      <td>-0.374364</td>\n","      <td>-0.374433</td>\n","      <td>-1.184939</td>\n","      <td>-0.016932</td>\n","      <td>-0.374561</td>\n","      <td>0.734337</td>\n","      <td>-0.909228</td>\n","      <td>-1.027389</td>\n","      <td>-0.068555</td>\n","      <td>-0.480194</td>\n","      <td>-0.289105</td>\n","      <td>1.608750</td>\n","      <td>1.618946</td>\n","      <td>-0.387635</td>\n","      <td>-0.376389</td>\n","      <td>0.652822</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.623390</td>\n","      <td>1.602655</td>\n","      <td>1.605095</td>\n","      <td>-0.374364</td>\n","      <td>-0.374433</td>\n","      <td>-1.298673</td>\n","      <td>-0.072391</td>\n","      <td>-0.374561</td>\n","      <td>0.734337</td>\n","      <td>-0.836962</td>\n","      <td>-0.960566</td>\n","      <td>-0.174419</td>\n","      <td>-0.480194</td>\n","      <td>-0.289105</td>\n","      <td>1.608750</td>\n","      <td>1.618946</td>\n","      <td>-0.387635</td>\n","      <td>-0.376389</td>\n","      <td>0.652822</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae705f42-c801-4a00-a9fd-fb67d820f0ce')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ae705f42-c801-4a00-a9fd-fb67d820f0ce button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ae705f42-c801-4a00-a9fd-fb67d820f0ce');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["far_df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1688940296202,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"Zf3vwcyFLd86","outputId":"c0f4e10e-f6da-451b-df86-6c2757f9aa95"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8000, 20)"]},"metadata":{},"execution_count":6}],"source":["far_df.shape"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1688940296202,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"z6SDbzWaohjU"},"outputs":[],"source":["far_y = far_df['Anomaly Flag']"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1688940296203,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"cc5YUUaw7Pm3","outputId":"7b1781db-6c30-4d16-c339-2cd469fa6962"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0    7500\n","1.0     500\n","Name: Anomaly Flag, dtype: int64"]},"metadata":{},"execution_count":8}],"source":["far_y.value_counts()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1688940296203,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"LkhSBiresxyZ"},"outputs":[],"source":["far_y_train = far_y[0:7000].to_numpy()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1688940296203,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"54tuMDr70R8t"},"outputs":[],"source":["far_y_out_test = far_y[7000:7500].to_numpy()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1688940296203,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"sBKXiE_BHdhf"},"outputs":[],"source":["far_y_norm_test = far_y[7500:8000].to_numpy()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":163,"status":"ok","timestamp":1688940296357,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"msNv_Jwxs3b4","outputId":"93bc4fcd-a9b9-4e76-dd98-4638f4da1b5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["(7000,) <class 'numpy.ndarray'> (array([0.]), array([7000])) (array([0.]), array([500])) (array([1.]), array([500]))\n"]}],"source":["print(far_y_train.shape, type(far_y_train), np.unique(far_y_train, return_counts=True), np.unique(far_y_norm_test, return_counts=True), np.unique(far_y_out_test, return_counts=True))"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1688940296357,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"dljYkWvXoUTQ"},"outputs":[],"source":["far_X = far_df.drop('Anomaly Flag', axis=1)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1688940296358,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"WGEchI6Lt1qv"},"outputs":[],"source":["far_X_train = far_X[0:7000].to_numpy()"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1688940296359,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"ijiaTx54xJKU"},"outputs":[],"source":["far_X_out_test = far_X[7000:7500].to_numpy()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1688940296359,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"w6JxTf4yH2Cm"},"outputs":[],"source":["far_X_norm_test = far_X[7500:8000].to_numpy()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1688940296359,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"R9VV5jcVuDiw","outputId":"b6ab3d65-fb5f-4491-e1ed-0ad93343246f"},"outputs":[{"output_type":"stream","name":"stdout","text":["(7000, 19) <class 'numpy.ndarray'> (500, 19) <class 'numpy.ndarray'> (500, 19) <class 'numpy.ndarray'>\n"]}],"source":["print(far_X_train.shape, type(far_X_train), far_X_out_test.shape, type(far_X_out_test), far_X_norm_test.shape, type(far_X_norm_test))"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":162,"status":"ok","timestamp":1688940296514,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"ldNOyaS_LfPF"},"outputs":[],"source":["near_df = pd.read_csv('/content/gdrive/Shareddrives/Anomaly/dataset/df_kae_near_nsl_kdd_5k_2k.csv')"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1688940296516,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"2ve4DYyKL_N1","outputId":"fe8ce9af-6d36-4de8-917d-41a8e325d63b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6000, 20)"]},"metadata":{},"execution_count":19}],"source":["near_df.shape"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1688940296516,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"UiGb7s8RMArD","outputId":"a234473c-d192-4eac-9b9e-9dcbfb381e86"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          2      0.00    0.00.1    0.00.2    0.00.3      1.00    0.00.4  \\\n","0  0.339641  1.602655  1.605095 -0.374364 -0.374433 -1.389660  0.038526   \n","1  0.322176 -0.637213 -0.631933  2.746390  2.715352 -1.139445 -0.016932   \n","2  0.715160  1.602655  1.605095 -0.374364 -0.374433 -1.389660 -0.016932   \n","3  0.287244  1.602655  1.605095 -0.374364 -0.374433 -1.184939 -0.016932   \n","4  1.623390  1.602655  1.605095 -0.374364 -0.374433 -1.298673 -0.072391   \n","\n","     0.00.5       150        25    0.17.1      0.03    0.17.2    0.00.6  \\\n","0 -0.374561  0.734337 -0.809862 -0.938292 -0.174419 -0.480194 -0.289105   \n","1 -0.374561  0.734337 -0.873095 -1.005115 -0.068555 -0.480194 -0.289105   \n","2 -0.374561  0.734337 -0.963427 -1.071937 -0.174419 -0.480194 -0.289105   \n","3 -0.374561  0.734337 -0.909228 -1.027389 -0.068555 -0.480194 -0.289105   \n","4 -0.374561  0.734337 -0.836962 -0.960566 -0.174419 -0.480194 -0.289105   \n","\n","     0.00.7    0.00.8      0.05    0.00.9        20  Anomaly Flag  \n","0  1.608750  1.618946 -0.387635 -0.376389 -0.219968           0.0  \n","1 -0.639535 -0.624874  2.874397  2.753901  0.652822           0.0  \n","2  1.608750  1.618946 -0.387635 -0.376389  0.652822           0.0  \n","3  1.608750  1.618946 -0.387635 -0.376389  0.652822           0.0  \n","4  1.608750  1.618946 -0.387635 -0.376389  0.652822           0.0  "],"text/html":["\n","  <div id=\"df-d72cbd2b-4a34-4864-9ee4-338483b1a454\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>0.00</th>\n","      <th>0.00.1</th>\n","      <th>0.00.2</th>\n","      <th>0.00.3</th>\n","      <th>1.00</th>\n","      <th>0.00.4</th>\n","      <th>0.00.5</th>\n","      <th>150</th>\n","      <th>25</th>\n","      <th>0.17.1</th>\n","      <th>0.03</th>\n","      <th>0.17.2</th>\n","      <th>0.00.6</th>\n","      <th>0.00.7</th>\n","      <th>0.00.8</th>\n","      <th>0.05</th>\n","      <th>0.00.9</th>\n","      <th>20</th>\n","      <th>Anomaly Flag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.339641</td>\n","      <td>1.602655</td>\n","      <td>1.605095</td>\n","      <td>-0.374364</td>\n","      <td>-0.374433</td>\n","      <td>-1.389660</td>\n","      <td>0.038526</td>\n","      <td>-0.374561</td>\n","      <td>0.734337</td>\n","      <td>-0.809862</td>\n","      <td>-0.938292</td>\n","      <td>-0.174419</td>\n","      <td>-0.480194</td>\n","      <td>-0.289105</td>\n","      <td>1.608750</td>\n","      <td>1.618946</td>\n","      <td>-0.387635</td>\n","      <td>-0.376389</td>\n","      <td>-0.219968</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.322176</td>\n","      <td>-0.637213</td>\n","      <td>-0.631933</td>\n","      <td>2.746390</td>\n","      <td>2.715352</td>\n","      <td>-1.139445</td>\n","      <td>-0.016932</td>\n","      <td>-0.374561</td>\n","      <td>0.734337</td>\n","      <td>-0.873095</td>\n","      <td>-1.005115</td>\n","      <td>-0.068555</td>\n","      <td>-0.480194</td>\n","      <td>-0.289105</td>\n","      <td>-0.639535</td>\n","      <td>-0.624874</td>\n","      <td>2.874397</td>\n","      <td>2.753901</td>\n","      <td>0.652822</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.715160</td>\n","      <td>1.602655</td>\n","      <td>1.605095</td>\n","      <td>-0.374364</td>\n","      <td>-0.374433</td>\n","      <td>-1.389660</td>\n","      <td>-0.016932</td>\n","      <td>-0.374561</td>\n","      <td>0.734337</td>\n","      <td>-0.963427</td>\n","      <td>-1.071937</td>\n","      <td>-0.174419</td>\n","      <td>-0.480194</td>\n","      <td>-0.289105</td>\n","      <td>1.608750</td>\n","      <td>1.618946</td>\n","      <td>-0.387635</td>\n","      <td>-0.376389</td>\n","      <td>0.652822</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.287244</td>\n","      <td>1.602655</td>\n","      <td>1.605095</td>\n","      <td>-0.374364</td>\n","      <td>-0.374433</td>\n","      <td>-1.184939</td>\n","      <td>-0.016932</td>\n","      <td>-0.374561</td>\n","      <td>0.734337</td>\n","      <td>-0.909228</td>\n","      <td>-1.027389</td>\n","      <td>-0.068555</td>\n","      <td>-0.480194</td>\n","      <td>-0.289105</td>\n","      <td>1.608750</td>\n","      <td>1.618946</td>\n","      <td>-0.387635</td>\n","      <td>-0.376389</td>\n","      <td>0.652822</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.623390</td>\n","      <td>1.602655</td>\n","      <td>1.605095</td>\n","      <td>-0.374364</td>\n","      <td>-0.374433</td>\n","      <td>-1.298673</td>\n","      <td>-0.072391</td>\n","      <td>-0.374561</td>\n","      <td>0.734337</td>\n","      <td>-0.836962</td>\n","      <td>-0.960566</td>\n","      <td>-0.174419</td>\n","      <td>-0.480194</td>\n","      <td>-0.289105</td>\n","      <td>1.608750</td>\n","      <td>1.618946</td>\n","      <td>-0.387635</td>\n","      <td>-0.376389</td>\n","      <td>0.652822</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d72cbd2b-4a34-4864-9ee4-338483b1a454')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d72cbd2b-4a34-4864-9ee4-338483b1a454 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d72cbd2b-4a34-4864-9ee4-338483b1a454');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}],"source":["near_df.head()"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1688940296516,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"OBIohNHoqN9o","outputId":"8dfa5432-8954-40c8-dd66-56399551f771"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 1.])"]},"metadata":{},"execution_count":21}],"source":["near_df['Anomaly Flag'].unique()"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1688940296776,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"IJ-Pbq9Swc_r"},"outputs":[],"source":["near_y = near_df['Anomaly Flag']"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1688940297069,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"nI5V9nF7wdIS"},"outputs":[],"source":["near_y_train = near_y[0:5000].to_numpy()"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1688940297215,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"I8beGT6P15EI"},"outputs":[],"source":["near_y_out_test = near_y[5000:5500].to_numpy()"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1688940297470,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"kpZkgcYJILdR"},"outputs":[],"source":["near_y_norm_test = near_y[5500:6000].to_numpy()"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1688940297696,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"HPcw8CWtwoWq","outputId":"03a6a336-b204-4df0-cdc7-29de819dc001"},"outputs":[{"output_type":"stream","name":"stdout","text":["(5000,) <class 'numpy.ndarray'> (array([0.]), array([5000])) (array([1.]), array([500])) (array([0.]), array([500]))\n"]}],"source":["print(near_y_train.shape, type(near_y_train), np.unique(near_y_train, return_counts=True), np.unique(near_y_out_test, return_counts=True), np.unique(near_y_norm_test, return_counts=True))"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":186,"status":"ok","timestamp":1688940298295,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"TRFaP_n9wobu"},"outputs":[],"source":["near_X = near_df.drop('Anomaly Flag', axis=1)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1688940298568,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"ifatxZZNw2u8"},"outputs":[],"source":["near_X_train = near_X[0:5000].to_numpy()"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1688940298801,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"uYVZ5PUJ6Yns"},"outputs":[],"source":["near_X_out_test = near_X[5000:5500].to_numpy()"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1688940299156,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"vkSqyjzXId6N"},"outputs":[],"source":["near_X_norm_test = near_X[5500:6000].to_numpy()"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1688940299589,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"2eDenzVOw2zN","outputId":"3ac07e0f-d4d5-4085-bee1-9cb63fad0ed9"},"outputs":[{"output_type":"stream","name":"stdout","text":["(5000, 19) <class 'numpy.ndarray'> (500, 19) <class 'numpy.ndarray'> (500, 19) <class 'numpy.ndarray'>\n"]}],"source":["print(near_X_train.shape, type(near_X_train), near_X_out_test.shape, type(near_X_out_test), near_X_norm_test.shape, type(near_X_norm_test))"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":98,"status":"ok","timestamp":1688940316664,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"ivDI2dCKNX_R"},"outputs":[],"source":["from models.ae import AutoencoderModel\n","from models.pca import PCAModel\n","from models.ocsvm import SVMModel\n","from models.vae import VAEModel\n","from models.isolationforest import IsolationForestModel\n","from models.knn import KNNModel\n","from models.ae_knn import AEKNNModel\n","# from models.bigan import BiGANModel\n","# from models.seq2seq import Seq2SeqModel\n","from utils import eval_utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3BAyrYg7Iv4E"},"outputs":[],"source":["def train_pca(in_train, in_test, out_test):\n","    num_features = 2\n","    pca = PCAModel()\n","    pca.train(in_train, in_test, num_features=num_features)\n","\n","    inlier_scores = pca.compute_anomaly_score_unsupervised(in_test)\n","    outlier_scores = pca.compute_anomaly_score_unsupervised(out_test)\n","    #print(inlier_scores)\n","    #print(outlier_scores)\n","    metrics = eval_utils.evaluate_model(\n","        inlier_scores, outlier_scores, model_name=\"pca\", show_plot=False)\n","    #print(metrics)\n","    return metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3674,"status":"ok","timestamp":1688334893341,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"8Ym7QNOtI2pd","outputId":"3273d9e1-5a0b-45a3-9358-53f5f9c3ed24"},"outputs":[{"name":"stdout","output_type":"stream","text":["Explained variation per principal component:  0.7082143683221611\n"]}],"source":["pca_far_metrics = train_pca(far_X_train, far_X_norm_test, far_X_out_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1688334893341,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"alFwDKyuJ0d4","outputId":"5ad4e5fe-0aaf-4687-a867-7c7a61009727"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'acc': 0.939, 'precision': 0.9954853273137697, 'recall': 0.882, 'f1': 0.9353128313891834, 'f2': 0.9025787965616046, 'roc': 0.9387800000000001, 'threshold': 10.406}\n"]}],"source":["print(pca_far_metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1592,"status":"ok","timestamp":1688334894929,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"pxkMwv3hJ4qv","outputId":"72bdee23-e2de-4105-ebf4-ccb2b333407f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Explained variation per principal component:  0.7096666634293693\n"]}],"source":["pca_near_metrics = train_pca(near_X_train, near_X_norm_test, near_X_out_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1688334894929,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"9r7avKezKAqe","outputId":"e6da4a8b-f3d9-43dd-c805-0db680415389"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'acc': 0.785, 'precision': 0.7378964941569283, 'recall': 0.884, 'f1': 0.8043676069153777, 'f2': 0.8503270488649481, 'roc': 0.7284759999999999, 'threshold': 10.325}\n"]}],"source":["print(pca_near_metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cz98dxKAJl1F"},"outputs":[],"source":["def train_svm(in_train, in_test, out_test):\n","    svm_kwargs = {}\n","    svm_kwargs[\"kernel\"] = \"rbf\"\n","    svm_kwargs[\"gamma\"] = 0.5\n","    svm_kwargs[\"outlier_frac\"] = 0.0001\n","    svm = SVMModel(**svm_kwargs)\n","    svm.train(in_train, in_test)\n","\n","    inlier_scores = svm.compute_anomaly_score(in_test)\n","    outlier_scores = svm.compute_anomaly_score(out_test)\n","    #print(inlier_scores)\n","    #print(outlier_scores)\n","    metrics = eval_utils.evaluate_model(\n","        inlier_scores, outlier_scores, model_name=\"ocsvm\", show_plot=False)\n","    #print(metrics)\n","    return metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqihwg62KT2t"},"outputs":[],"source":["svm_far_metrics = train_svm(far_X_train, far_X_norm_test,  far_X_out_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1688334897736,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"XZ24mIF1KceE","outputId":"b771f25a-b18c-4e9e-e7a2-729a7a4111e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'acc': 0.984, 'precision': 1.0, 'recall': 0.968, 'f1': 0.983739837398374, 'f2': 0.9742351046698873, 'roc': 0.99742, 'threshold': 0.001}\n"]}],"source":["print(svm_far_metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h9cyxYY_Kgmz"},"outputs":[],"source":["svm_near_metrics = train_svm(near_X_train, near_X_norm_test, near_X_out_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1688334899206,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"mRpEacDXKmvE","outputId":"71d5ae96-33c3-4df1-e301-5e9acf53c6fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'acc': 0.971, 'precision': 0.9719438877755511, 'recall': 0.97, 'f1': 0.970970970970971, 'f2': 0.9703881552621049, 'roc': 0.995472, 'threshold': 0.001}\n"]}],"source":["print(svm_near_metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ef71SLLTLX1I"},"outputs":[],"source":["def train_autoencoder(in_train, in_test, out_test):\n","    # Instantiate and Train Autoencoder\n","    ae_kwargs = {}\n","    ae_kwargs[\"latent_dim\"] = 2\n","    ae_kwargs[\"hidden_layers\"] = 1\n","    ae_kwargs[\"hidden_dim\"] = [7]\n","    ae_kwargs[\"epochs\"] = 50\n","    ae_kwargs[\"batch_size\"] = 2\n","    ae_kwargs[\"learning_rate\"] = 0.001\n","    # ae_kwargs[\"model_path\"] = ae_model_path\n","    ae = AutoencoderModel(in_train.shape[1], **ae_kwargs)\n","    ae.train(in_train, in_test)\n","    ae.save_model()\n","\n","    inlier_scores = ae.compute_anomaly_score(in_test, \"mae\")\n","    outlier_scores = ae.compute_anomaly_score(out_test, \"mae\")\n","    # print(inlier_scores)\n","    # print(outlier_scores)\n","    metrics = eval_utils.evaluate_model(\n","        inlier_scores, outlier_scores, model_name=\"ae\", show_plot=False)\n","    #print(metrics)\n","    return metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":386330,"status":"ok","timestamp":1688337530910,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"ufeTPvt2Li3G","outputId":"a8313ba2-9e9c-41e5-c49c-5ede398c2b53"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"encoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," encoder_input (InputLayer)  [(None, 19)]              0         \n","                                                                 \n"," encoder_hidden_0 (Dense)    (None, 7)                 140       \n","                                                                 \n"," z_ (Dense)                  (None, 2)                 16        \n","                                                                 \n","=================================================================\n","Total params: 156\n","Trainable params: 156\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"decoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," z_ (InputLayer)             [(None, 2)]               0         \n","                                                                 \n"," decoder_hidden_0 (Dense)    (None, 7)                 21        \n","                                                                 \n"," decoder_output (Dense)      (None, 19)                152       \n","                                                                 \n","=================================================================\n","Total params: 173\n","Trainable params: 173\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.8452 - val_loss: 0.4233\n","Epoch 2/50\n","3500/3500 [==============================] - 9s 2ms/step - loss: 0.7695 - val_loss: 0.4096\n","Epoch 3/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7629 - val_loss: 0.4078\n","Epoch 4/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7605 - val_loss: 0.4072\n","Epoch 5/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7594 - val_loss: 0.4065\n","Epoch 6/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7584 - val_loss: 0.4061\n","Epoch 7/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7572 - val_loss: 0.4048\n","Epoch 8/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7564 - val_loss: 0.4045\n","Epoch 9/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7557 - val_loss: 0.4040\n","Epoch 10/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7555 - val_loss: 0.4041\n","Epoch 11/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7536 - val_loss: 0.4012\n","Epoch 12/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7523 - val_loss: 0.3998\n","Epoch 13/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7514 - val_loss: 0.3989\n","Epoch 14/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7506 - val_loss: 0.3978\n","Epoch 15/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7500 - val_loss: 0.3985\n","Epoch 16/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7485 - val_loss: 0.3976\n","Epoch 17/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7479 - val_loss: 0.3969\n","Epoch 18/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7476 - val_loss: 0.3970\n","Epoch 19/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7474 - val_loss: 0.3963\n","Epoch 20/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7472 - val_loss: 0.3964\n","Epoch 21/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7471 - val_loss: 0.3959\n","Epoch 22/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7469 - val_loss: 0.3963\n","Epoch 23/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7469 - val_loss: 0.3962\n","Epoch 24/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7467 - val_loss: 0.3958\n","Epoch 25/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7466 - val_loss: 0.3957\n","Epoch 26/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7465 - val_loss: 0.3961\n","Epoch 27/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7463 - val_loss: 0.3956\n","Epoch 28/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7464 - val_loss: 0.3956\n","Epoch 29/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7462 - val_loss: 0.3957\n","Epoch 30/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7461 - val_loss: 0.3954\n","Epoch 31/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7459 - val_loss: 0.3956\n","Epoch 32/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7459 - val_loss: 0.3958\n","Epoch 33/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7459 - val_loss: 0.3954\n","Epoch 34/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7456 - val_loss: 0.3953\n","Epoch 35/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7457 - val_loss: 0.3951\n","Epoch 36/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7455 - val_loss: 0.3950\n","Epoch 37/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7454 - val_loss: 0.3953\n","Epoch 38/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7455 - val_loss: 0.3956\n","Epoch 39/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7453 - val_loss: 0.3949\n","Epoch 40/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7453 - val_loss: 0.3951\n","Epoch 41/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7453 - val_loss: 0.3950\n","Epoch 42/50\n","3500/3500 [==============================] - 6s 2ms/step - loss: 0.7452 - val_loss: 0.3948\n","Epoch 43/50\n","3500/3500 [==============================] - 8s 2ms/step - loss: 0.7450 - val_loss: 0.3948\n","Epoch 44/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7450 - val_loss: 0.3950\n","Epoch 45/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7448 - val_loss: 0.3947\n","Epoch 46/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7447 - val_loss: 0.3947\n","Epoch 47/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7447 - val_loss: 0.3947\n","Epoch 48/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7447 - val_loss: 0.3945\n","Epoch 49/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7445 - val_loss: 0.3945\n","Epoch 50/50\n","3500/3500 [==============================] - 7s 2ms/step - loss: 0.7445 - val_loss: 0.3943\n","16/16 [==============================] - 0s 1ms/step\n","0.5084438894973947\n","16/16 [==============================] - 0s 2ms/step\n","0.9564893616866542\n"]}],"source":["ae_far_metrics = train_autoencoder(far_X_train, far_X_norm_test, far_X_out_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1688337530911,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"-n-ujTZzLtEu","outputId":"c4a1ae74-cab0-438f-ab92-afed228aae2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'acc': 0.964, 'precision': 0.94106463878327, 'recall': 0.99, 'f1': 0.9649122807017544, 'f2': 0.9798099762470307, 'roc': 0.9949680000000001, 'threshold': 0.669}\n"]}],"source":["print(ae_far_metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263694,"status":"ok","timestamp":1688337794595,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"6FoGMwN4MJdt","outputId":"1869eb35-927d-46cb-9fef-f9cb6b6c92cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"encoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," encoder_input (InputLayer)  [(None, 19)]              0         \n","                                                                 \n"," encoder_hidden_0 (Dense)    (None, 7)                 140       \n","                                                                 \n"," z_ (Dense)                  (None, 2)                 16        \n","                                                                 \n","=================================================================\n","Total params: 156\n","Trainable params: 156\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"decoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," z_ (InputLayer)             [(None, 2)]               0         \n","                                                                 \n"," decoder_hidden_0 (Dense)    (None, 7)                 21        \n","                                                                 \n"," decoder_output (Dense)      (None, 19)                152       \n","                                                                 \n","=================================================================\n","Total params: 173\n","Trainable params: 173\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","2500/2500 [==============================] - 7s 3ms/step - loss: 0.9233 - val_loss: 0.8781\n","Epoch 2/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7873 - val_loss: 0.8542\n","Epoch 3/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7682 - val_loss: 0.8444\n","Epoch 4/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7596 - val_loss: 0.8319\n","Epoch 5/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7508 - val_loss: 0.8273\n","Epoch 6/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7479 - val_loss: 0.8245\n","Epoch 7/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7457 - val_loss: 0.8227\n","Epoch 8/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7444 - val_loss: 0.8213\n","Epoch 9/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7432 - val_loss: 0.8194\n","Epoch 10/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7422 - val_loss: 0.8195\n","Epoch 11/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7416 - val_loss: 0.8181\n","Epoch 12/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7410 - val_loss: 0.8176\n","Epoch 13/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7407 - val_loss: 0.8176\n","Epoch 14/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7402 - val_loss: 0.8166\n","Epoch 15/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7400 - val_loss: 0.8161\n","Epoch 16/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7397 - val_loss: 0.8159\n","Epoch 17/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7392 - val_loss: 0.8162\n","Epoch 18/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7392 - val_loss: 0.8165\n","Epoch 19/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7388 - val_loss: 0.8154\n","Epoch 20/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7385 - val_loss: 0.8156\n","Epoch 21/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7384 - val_loss: 0.8147\n","Epoch 22/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7383 - val_loss: 0.8150\n","Epoch 23/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7382 - val_loss: 0.8155\n","Epoch 24/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7384 - val_loss: 0.8155\n","Epoch 25/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7379 - val_loss: 0.8149\n","Epoch 26/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7381 - val_loss: 0.8146\n","Epoch 27/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7377 - val_loss: 0.8148\n","Epoch 28/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7379 - val_loss: 0.8141\n","Epoch 29/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7377 - val_loss: 0.8142\n","Epoch 30/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7375 - val_loss: 0.8155\n","Epoch 31/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7379 - val_loss: 0.8144\n","Epoch 32/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7376 - val_loss: 0.8142\n","Epoch 33/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7373 - val_loss: 0.8160\n","Epoch 34/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7376 - val_loss: 0.8171\n","Epoch 35/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7376 - val_loss: 0.8146\n","Epoch 36/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7375 - val_loss: 0.8146\n","Epoch 37/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7371 - val_loss: 0.8140\n","Epoch 38/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7373 - val_loss: 0.8153\n","Epoch 39/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7371 - val_loss: 0.8144\n","Epoch 40/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7371 - val_loss: 0.8139\n","Epoch 41/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7372 - val_loss: 0.8144\n","Epoch 42/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7369 - val_loss: 0.8146\n","Epoch 43/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7369 - val_loss: 0.8136\n","Epoch 44/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7369 - val_loss: 0.8143\n","Epoch 45/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7369 - val_loss: 0.8145\n","Epoch 46/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7371 - val_loss: 0.8147\n","Epoch 47/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7367 - val_loss: 0.8144\n","Epoch 48/50\n","2500/2500 [==============================] - 6s 2ms/step - loss: 0.7368 - val_loss: 0.8145\n","Epoch 49/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7366 - val_loss: 0.8148\n","Epoch 50/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.7366 - val_loss: 0.8140\n","16/16 [==============================] - 0s 1ms/step\n","0.6430803939676436\n","16/16 [==============================] - 0s 2ms/step\n","1.025339279670579\n"]}],"source":["ae_near_metrics = train_autoencoder(near_X_train, near_X_norm_test, near_X_out_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1688337794596,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"},"user_tz":240},"id":"ufPuWbmUMQaJ","outputId":"4238c0d5-3888-4e40-afc8-83931d1acc5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'acc': 0.837, 'precision': 0.813780260707635, 'recall': 0.874, 'f1': 0.8428158148505304, 'f2': 0.8612534489554592, 'roc': 0.882108, 'threshold': 1.04}\n"]}],"source":["print(ae_near_metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pxgZbsdgMbO7"},"outputs":[],"source":["def train_vae(in_train, in_test, out_test):\n","    # Instantiate and Train Autoencoder\n","    vae_kwargs = {}\n","    vae_kwargs[\"latent_dim\"] = 2\n","    vae_kwargs[\"hidden_dim\"] = [15, 7]\n","    vae_kwargs[\"epochs\"] = 50\n","    vae_kwargs[\"batch_size\"] = 8\n","    # vae_kwargs[\"model_path\"] = ae_model_path\n","    vae = VAEModel(in_train.shape[1], **vae_kwargs)\n","    vae.train(in_train, in_test)\n","    vae.save_model()\n","\n","    inlier_scores = vae.compute_anomaly_score(in_test, \"mae\")\n","    outlier_scores = vae.compute_anomaly_score(out_test, \"mae\")\n","    # print(inlier_scores)\n","    # print(outlier_scores)\n","    metrics = eval_utils.evaluate_model(\n","        inlier_scores, outlier_scores, model_name=\"vae\", show_plot=False)\n","    # print(metrics)\n","    return metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ksoQxmauMl8H","outputId":"d2b905e5-b7dc-4e6a-c212-71c6c49660d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"encoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_input (InputLayer)     [(None, 19)]         0           []                               \n","                                                                                                  \n"," encoder_hidden_0 (Dense)       (None, 15)           300         ['encoder_input[0][0]']          \n","                                                                                                  \n"," encoder_hidden_1 (Dense)       (None, 7)            112         ['encoder_hidden_0[0][0]']       \n","                                                                                                  \n"," z_mean (Dense)                 (None, 2)            16          ['encoder_hidden_1[0][0]']       \n","                                                                                                  \n"," z_log_var (Dense)              (None, 2)            16          ['encoder_hidden_1[0][0]']       \n","                                                                                                  \n"," z (Lambda)                     (None, 2)            0           ['z_mean[0][0]',                 \n","                                                                  'z_log_var[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 444\n","Trainable params: 444\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"decoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," z_sampling (InputLayer)     [(None, 2)]               0         \n","                                                                 \n"," decoder_hidden_0 (Dense)    (None, 7)                 21        \n","                                                                 \n"," decoder_hidden_1 (Dense)    (None, 15)                120       \n","                                                                 \n"," decoder_output (Dense)      (None, 19)                304       \n","                                                                 \n","=================================================================\n","Total params: 445\n","Trainable params: 445\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","875/875 [==============================] - 4s 3ms/step - loss: 21.8083 - val_loss: 10.2622\n","Epoch 2/50\n","875/875 [==============================] - 2s 2ms/step - loss: 18.6398 - val_loss: 9.9209\n","Epoch 3/50\n","875/875 [==============================] - 2s 2ms/step - loss: 17.4713 - val_loss: 9.5971\n","Epoch 4/50\n","875/875 [==============================] - 2s 2ms/step - loss: 17.3056 - val_loss: 9.5535\n","Epoch 5/50\n","875/875 [==============================] - 2s 3ms/step - loss: 17.1945 - val_loss: 9.5752\n","Epoch 6/50\n","875/875 [==============================] - 3s 3ms/step - loss: 17.0660 - val_loss: 9.5222\n","Epoch 7/50\n","875/875 [==============================] - 3s 3ms/step - loss: 16.9766 - val_loss: 9.4127\n","Epoch 8/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.8594 - val_loss: 9.4444\n","Epoch 9/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.7942 - val_loss: 9.4930\n","Epoch 10/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.7625 - val_loss: 9.4433\n","Epoch 11/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.7384 - val_loss: 9.3304\n","Epoch 12/50\n","875/875 [==============================] - 3s 3ms/step - loss: 16.7187 - val_loss: 9.3285\n","Epoch 13/50\n","875/875 [==============================] - 3s 3ms/step - loss: 16.6735 - val_loss: 9.3178\n","Epoch 14/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.6623 - val_loss: 9.3722\n","Epoch 15/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.6845 - val_loss: 9.2215\n","Epoch 16/50\n","875/875 [==============================] - 2s 3ms/step - loss: 16.6655 - val_loss: 9.3382\n","Epoch 17/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.6452 - val_loss: 9.3338\n","Epoch 18/50\n","875/875 [==============================] - 3s 3ms/step - loss: 16.6233 - val_loss: 9.2420\n","Epoch 19/50\n","875/875 [==============================] - 3s 3ms/step - loss: 16.6203 - val_loss: 9.3579\n","Epoch 20/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.6126 - val_loss: 9.2322\n","Epoch 21/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.6202 - val_loss: 9.3679\n","Epoch 22/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5932 - val_loss: 9.2185\n","Epoch 23/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.6149 - val_loss: 9.2517\n","Epoch 24/50\n","875/875 [==============================] - 3s 3ms/step - loss: 16.6069 - val_loss: 9.1807\n","Epoch 25/50\n","875/875 [==============================] - 3s 3ms/step - loss: 16.6357 - val_loss: 9.2644\n","Epoch 26/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5938 - val_loss: 9.2693\n","Epoch 27/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5978 - val_loss: 9.3190\n","Epoch 28/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.6137 - val_loss: 9.2714\n","Epoch 29/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5559 - val_loss: 9.3461\n","Epoch 30/50\n","875/875 [==============================] - 2s 3ms/step - loss: 16.6112 - val_loss: 9.2319\n","Epoch 31/50\n","875/875 [==============================] - 3s 3ms/step - loss: 16.5966 - val_loss: 9.2471\n","Epoch 32/50\n","875/875 [==============================] - 2s 3ms/step - loss: 16.5498 - val_loss: 9.2055\n","Epoch 33/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5518 - val_loss: 9.1710\n","Epoch 34/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5269 - val_loss: 9.3804\n","Epoch 35/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5236 - val_loss: 9.1667\n","Epoch 36/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5323 - val_loss: 9.2783\n","Epoch 37/50\n","875/875 [==============================] - 3s 3ms/step - loss: 16.5121 - val_loss: 9.1149\n","Epoch 38/50\n","875/875 [==============================] - 2s 3ms/step - loss: 16.5022 - val_loss: 9.1557\n","Epoch 39/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5087 - val_loss: 9.2517\n","Epoch 40/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5351 - val_loss: 9.2865\n","Epoch 41/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5092 - val_loss: 9.1777\n","Epoch 42/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5308 - val_loss: 9.1103\n","Epoch 43/50\n","875/875 [==============================] - 3s 3ms/step - loss: 16.5184 - val_loss: 9.2402\n","Epoch 44/50\n","875/875 [==============================] - 3s 3ms/step - loss: 16.5017 - val_loss: 9.2922\n","Epoch 45/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.5407 - val_loss: 9.1466\n","Epoch 46/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.4601 - val_loss: 9.1948\n","Epoch 47/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.4953 - val_loss: 9.2806\n","Epoch 48/50\n","875/875 [==============================] - 2s 2ms/step - loss: 16.4695 - val_loss: 9.3316\n","Epoch 49/50\n","875/875 [==============================] - 2s 3ms/step - loss: 16.4770 - val_loss: 9.2192\n","Epoch 50/50\n","875/875 [==============================] - 3s 4ms/step - loss: 16.4791 - val_loss: 9.2917\n","16/16 [==============================] - 0s 2ms/step\n","0.5376481403414596\n","16/16 [==============================] - 0s 2ms/step\n","1.0154525837149389\n"]}],"source":["vae_far_metrics = train_vae(far_X_train, far_X_norm_test, far_X_out_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"92ylhESXMq3P","outputId":"efabc07b-f67a-4292-ee67-acf45d12ab88"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'acc': 0.957, 'precision': 0.9271028037383178, 'recall': 0.992, 'f1': 0.9584541062801932, 'f2': 0.9783037475345169, 'roc': 0.991664, 'threshold': 0.743}\n"]}],"source":["print(vae_far_metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yAxE2FqnMwqH","outputId":"b723b79a-af00-4100-c6bb-5cb952c32bc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"encoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_input (InputLayer)     [(None, 19)]         0           []                               \n","                                                                                                  \n"," encoder_hidden_0 (Dense)       (None, 15)           300         ['encoder_input[0][0]']          \n","                                                                                                  \n"," encoder_hidden_1 (Dense)       (None, 7)            112         ['encoder_hidden_0[0][0]']       \n","                                                                                                  \n"," z_mean (Dense)                 (None, 2)            16          ['encoder_hidden_1[0][0]']       \n","                                                                                                  \n"," z_log_var (Dense)              (None, 2)            16          ['encoder_hidden_1[0][0]']       \n","                                                                                                  \n"," z (Lambda)                     (None, 2)            0           ['z_mean[0][0]',                 \n","                                                                  'z_log_var[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 444\n","Trainable params: 444\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model: \"decoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," z_sampling (InputLayer)     [(None, 2)]               0         \n","                                                                 \n"," decoder_hidden_0 (Dense)    (None, 7)                 21        \n","                                                                 \n"," decoder_hidden_1 (Dense)    (None, 15)                120       \n","                                                                 \n"," decoder_output (Dense)      (None, 19)                304       \n","                                                                 \n","=================================================================\n","Total params: 445\n","Trainable params: 445\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","625/625 [==============================] - 3s 3ms/step - loss: 24.6639 - val_loss: 21.1972\n","Epoch 2/50\n","625/625 [==============================] - 1s 2ms/step - loss: 19.0215 - val_loss: 19.9184\n","Epoch 3/50\n","625/625 [==============================] - 1s 2ms/step - loss: 18.0594 - val_loss: 19.3076\n","Epoch 4/50\n","625/625 [==============================] - 2s 3ms/step - loss: 17.5686 - val_loss: 18.8246\n","Epoch 5/50\n","625/625 [==============================] - 2s 4ms/step - loss: 17.3795 - val_loss: 18.6350\n","Epoch 6/50\n","625/625 [==============================] - 1s 2ms/step - loss: 17.2032 - val_loss: 18.4894\n","Epoch 7/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.9976 - val_loss: 18.4022\n","Epoch 8/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.9273 - val_loss: 18.3045\n","Epoch 9/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.8619 - val_loss: 18.3007\n","Epoch 10/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.8332 - val_loss: 18.2170\n","Epoch 11/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.8307 - val_loss: 18.2078\n","Epoch 12/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.7047 - val_loss: 18.0788\n","Epoch 13/50\n","625/625 [==============================] - 2s 4ms/step - loss: 16.7003 - val_loss: 18.0653\n","Epoch 14/50\n","625/625 [==============================] - 2s 3ms/step - loss: 16.6431 - val_loss: 18.0444\n","Epoch 15/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.6307 - val_loss: 17.8899\n","Epoch 16/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.6104 - val_loss: 18.1417\n","Epoch 17/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.6443 - val_loss: 18.0609\n","Epoch 18/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.5686 - val_loss: 17.8912\n","Epoch 19/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.6020 - val_loss: 18.0034\n","Epoch 20/50\n","625/625 [==============================] - 2s 2ms/step - loss: 16.5600 - val_loss: 17.9210\n","Epoch 21/50\n","625/625 [==============================] - 2s 3ms/step - loss: 16.5329 - val_loss: 17.8727\n","Epoch 22/50\n","625/625 [==============================] - 2s 3ms/step - loss: 16.5565 - val_loss: 17.8157\n","Epoch 23/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.5191 - val_loss: 17.8422\n","Epoch 24/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.5112 - val_loss: 17.8130\n","Epoch 25/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.5034 - val_loss: 17.8992\n","Epoch 26/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.5003 - val_loss: 17.8535\n","Epoch 27/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4631 - val_loss: 17.9363\n","Epoch 28/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4569 - val_loss: 17.8608\n","Epoch 29/50\n","625/625 [==============================] - 2s 3ms/step - loss: 16.4535 - val_loss: 17.8494\n","Epoch 30/50\n","625/625 [==============================] - 2s 4ms/step - loss: 16.4469 - val_loss: 17.9106\n","Epoch 31/50\n","625/625 [==============================] - 2s 3ms/step - loss: 16.5107 - val_loss: 17.7786\n","Epoch 32/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4472 - val_loss: 17.9130\n","Epoch 33/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4734 - val_loss: 17.8159\n","Epoch 34/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4314 - val_loss: 17.7853\n","Epoch 35/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4176 - val_loss: 17.8475\n","Epoch 36/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4568 - val_loss: 17.8025\n","Epoch 37/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4419 - val_loss: 17.8264\n","Epoch 38/50\n","625/625 [==============================] - 2s 3ms/step - loss: 16.4443 - val_loss: 17.8617\n","Epoch 39/50\n","625/625 [==============================] - 2s 4ms/step - loss: 16.4191 - val_loss: 17.6940\n","Epoch 40/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4231 - val_loss: 17.8133\n","Epoch 41/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4436 - val_loss: 17.7952\n","Epoch 42/50\n","625/625 [==============================] - 2s 2ms/step - loss: 16.4202 - val_loss: 17.8137\n","Epoch 43/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.3985 - val_loss: 17.7831\n","Epoch 44/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4123 - val_loss: 17.8452\n","Epoch 45/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.4047 - val_loss: 17.7950\n","Epoch 46/50\n","625/625 [==============================] - 2s 2ms/step - loss: 16.3812 - val_loss: 17.7970\n","Epoch 47/50\n","625/625 [==============================] - 2s 3ms/step - loss: 16.4152 - val_loss: 17.7680\n","Epoch 48/50\n","625/625 [==============================] - 2s 3ms/step - loss: 16.4006 - val_loss: 17.8261\n","Epoch 49/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.3892 - val_loss: 17.8084\n","Epoch 50/50\n","625/625 [==============================] - 1s 2ms/step - loss: 16.3825 - val_loss: 17.6795\n","16/16 [==============================] - 0s 2ms/step\n","0.668615064561134\n","16/16 [==============================] - 0s 2ms/step\n","1.0126359627588648\n"]}],"source":["vae_near_metrics = train_vae(near_X_train, near_X_norm_test, near_X_out_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lzik0LsMMwtT","outputId":"e62284e1-1849-455c-9258-761f69747972"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'acc': 0.833, 'precision': 0.8159392789373814, 'recall': 0.86, 'f1': 0.8373904576436222, 'f2': 0.850811238622873, 'roc': 0.8587159999999999, 'threshold': 1.119}\n"]}],"source":["print(vae_near_metrics)"]},{"cell_type":"code","source":["def train_isolationforest(in_train, in_test, out_test):\n","    contamination = 'auto'\n","    ifm = IsolationForestModel(contamination)\n","    ifm.train(in_train, in_test)\n","\n","    inlier_scores = ifm.compute_anomaly_score(in_test)\n","    outlier_scores = ifm.compute_anomaly_score(out_test)\n","    #print(inlier_scores)\n","    #print(outlier_scores)\n","    metrics = eval_utils.evaluate_model(\n","        inlier_scores, outlier_scores, model_name=\"isolationforest\", show_plot=False)\n","    #print(metrics)\n","    return metrics"],"metadata":{"id":"o2URkw6GyF51"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ifm_far_metrics = train_isolationforest(far_X_train, far_X_norm_test, far_X_out_test)"],"metadata":{"id":"ymhjaQTeyzpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ifm_far_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6bMLs_1zRJy","executionInfo":{"status":"ok","timestamp":1688489245566,"user_tz":240,"elapsed":4,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}},"outputId":"0e7e351a-aec5-49fa-e9c3-902dc85f0821"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'acc': 0.958, 'precision': 0.935361216730038, 'recall': 0.984, 'f1': 0.9590643274853801, 'f2': 0.9738717339667459, 'roc': 0.986724, 'threshold': 0.021}\n"]}]},{"cell_type":"code","source":["ifm_near_metrics = train_isolationforest(near_X_train, near_X_norm_test, near_X_out_test)"],"metadata":{"id":"y8vjR0wwzRRf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ifm_near_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nt0hkUMqzdU6","executionInfo":{"status":"ok","timestamp":1688489293639,"user_tz":240,"elapsed":3,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}},"outputId":"b3aebd88-ad28-4463-9ef6-a43f643c7880"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'acc': 0.901, 'precision': 0.8678899082568807, 'recall': 0.946, 'f1': 0.9052631578947368, 'f2': 0.9292730844793714, 'roc': 0.949248, 'threshold': 0.048}\n"]}]},{"cell_type":"code","source":["def train_knn(in_train, in_test, out_test):\n","    n = 3\n","    algorithm = 'auto'\n","    knn = KNNModel(n, algorithm)\n","    knn.train(in_train, in_test)\n","\n","    inlier_scores = knn.compute_anomaly_score(in_test)\n","    outlier_scores = knn.compute_anomaly_score(out_test)\n","    #print(inlier_scores.shape, type(inlier_scores))\n","    #print(outlier_scores)\n","    metrics = eval_utils.evaluate_model(\n","        inlier_scores, outlier_scores, model_name=\"knn\", show_plot=False)\n","    #print(metrics)\n","    return metrics"],"metadata":{"id":"iTILl1OeVGdJ","executionInfo":{"status":"ok","timestamp":1688934361358,"user_tz":240,"elapsed":130,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["knn_far_metrics = train_knn(far_X_train, far_X_norm_test, far_X_out_test)"],"metadata":{"id":"8rhiRvRsVTES","executionInfo":{"status":"ok","timestamp":1688934400119,"user_tz":240,"elapsed":3027,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["print(knn_far_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNqmcwvoVTH6","executionInfo":{"status":"ok","timestamp":1688934400119,"user_tz":240,"elapsed":5,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}},"outputId":"31269646-27de-4df5-8133-a7c9f69eb704"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["{'acc': 0.985, 'precision': 0.9764243614931237, 'recall': 0.994, 'f1': 0.9851337958374627, 'f2': 0.9904344360302909, 'roc': 0.9988199999999999, 'threshold': 0.417}\n"]}]},{"cell_type":"code","source":["knn_near_metrics = train_knn(near_X_train, near_X_norm_test, near_X_out_test)"],"metadata":{"id":"bbWS0kkGVTLQ","executionInfo":{"status":"ok","timestamp":1688934401562,"user_tz":240,"elapsed":1446,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["print(knn_near_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z18_1FdGVTPd","executionInfo":{"status":"ok","timestamp":1688934401724,"user_tz":240,"elapsed":166,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}},"outputId":"5fe78cde-eebe-4abe-b3ee-56b41abc543d"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["{'acc': 0.972, 'precision': 0.9738955823293173, 'recall': 0.97, 'f1': 0.9719438877755512, 'f2': 0.9707766212970377, 'roc': 0.9945599999999999, 'threshold': 1.428}\n"]}]},{"cell_type":"code","source":["def train_AEKNN(in_train, in_test, out_test):\n","    # Instantiate and Train Autoencoder\n","    ae_kwargs = {}\n","    ae_kwargs[\"latent_dim\"] = 3\n","    ae_kwargs[\"hidden_layers\"] = 2\n","    ae_kwargs[\"hidden_dim\"] = [15, 7]\n","    ae_kwargs[\"epochs\"] = 50\n","    ae_kwargs[\"batch_size\"] = 2\n","    ae_kwargs[\"learning_rate\"] = 0.001\n","    # ae_kwargs[\"model_path\"] = ae_model_path\n","    aeknn = AEKNNModel(in_train.shape[1], **ae_kwargs)\n","    aeknn.train(in_train, in_test)\n","    aeknn.save_model()\n","\n","    inlier_scores = aeknn.compute_anomaly_score(in_test, \"mae\")\n","    outlier_scores = aeknn.compute_anomaly_score(out_test, \"mae\")\n","    # print(inlier_scores)\n","    # print(outlier_scores)\n","    metrics = eval_utils.evaluate_model(\n","        inlier_scores, outlier_scores, model_name=\"aeknn\", show_plot=False)\n","    #print(metrics)\n","    return metrics"],"metadata":{"id":"E2IwAmbornJ0","executionInfo":{"status":"ok","timestamp":1688940331065,"user_tz":240,"elapsed":108,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["aeknn_far_metrics = train_AEKNN(far_X_train, far_X_norm_test, far_X_out_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxLSpbLTrn-p","executionInfo":{"status":"ok","timestamp":1688940598129,"user_tz":240,"elapsed":266177,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}},"outputId":"b87a3ef6-2a84-4f64-a9ff-16450738a822"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"encoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," encoder_input (InputLayer)  [(None, 19)]              0         \n","                                                                 \n"," encoder_hidden_0 (Dense)    (None, 15)                300       \n","                                                                 \n"," encoder_hidden_1 (Dense)    (None, 7)                 112       \n","                                                                 \n"," z_ (Dense)                  (None, 3)                 24        \n","                                                                 \n","=================================================================\n","Total params: 436\n","Trainable params: 436\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"decoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," z_ (InputLayer)             [(None, 3)]               0         \n","                                                                 \n"," decoder_hidden_0 (Dense)    (None, 7)                 28        \n","                                                                 \n"," decoder_hidden_1 (Dense)    (None, 15)                120       \n","                                                                 \n"," decoder_output (Dense)      (None, 19)                304       \n","                                                                 \n","=================================================================\n","Total params: 452\n","Trainable params: 452\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.8377 - val_loss: 0.4127\n","Epoch 2/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7655 - val_loss: 0.4082\n","Epoch 3/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7535 - val_loss: 0.4010\n","Epoch 4/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7483 - val_loss: 0.3979\n","Epoch 5/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7453 - val_loss: 0.3965\n","Epoch 6/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7434 - val_loss: 0.3960\n","Epoch 7/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7400 - val_loss: 0.3912\n","Epoch 8/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7386 - val_loss: 0.3902\n","Epoch 9/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7378 - val_loss: 0.3896\n","Epoch 10/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7366 - val_loss: 0.3886\n","Epoch 11/50\n","3500/3500 [==============================] - 5s 2ms/step - loss: 0.7368 - val_loss: 0.3883\n","Epoch 12/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7359 - val_loss: 0.3886\n","Epoch 13/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7358 - val_loss: 0.3872\n","Epoch 14/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7359 - val_loss: 0.3871\n","Epoch 15/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7356 - val_loss: 0.3874\n","Epoch 16/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7355 - val_loss: 0.3870\n","Epoch 17/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7349 - val_loss: 0.3874\n","Epoch 18/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7349 - val_loss: 0.3872\n","Epoch 19/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7348 - val_loss: 0.3869\n","Epoch 20/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7348 - val_loss: 0.3866\n","Epoch 21/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7342 - val_loss: 0.3866\n","Epoch 22/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7349 - val_loss: 0.3865\n","Epoch 23/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7342 - val_loss: 0.3866\n","Epoch 24/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7343 - val_loss: 0.3864\n","Epoch 25/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7345 - val_loss: 0.3867\n","Epoch 26/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7344 - val_loss: 0.3863\n","Epoch 27/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7340 - val_loss: 0.3864\n","Epoch 28/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7340 - val_loss: 0.3863\n","Epoch 29/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7343 - val_loss: 0.3862\n","Epoch 30/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7339 - val_loss: 0.3857\n","Epoch 31/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7339 - val_loss: 0.3860\n","Epoch 32/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7342 - val_loss: 0.3869\n","Epoch 33/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7344 - val_loss: 0.3860\n","Epoch 34/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7339 - val_loss: 0.3857\n","Epoch 35/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7337 - val_loss: 0.3860\n","Epoch 36/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7331 - val_loss: 0.3863\n","Epoch 37/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7329 - val_loss: 0.3862\n","Epoch 38/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7333 - val_loss: 0.3859\n","Epoch 39/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7330 - val_loss: 0.3857\n","Epoch 40/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7328 - val_loss: 0.3855\n","Epoch 41/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7327 - val_loss: 0.3859\n","Epoch 42/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7331 - val_loss: 0.3855\n","Epoch 43/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7328 - val_loss: 0.3859\n","Epoch 44/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7335 - val_loss: 0.3866\n","Epoch 45/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7324 - val_loss: 0.3864\n","Epoch 46/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7332 - val_loss: 0.3852\n","Epoch 47/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7325 - val_loss: 0.3854\n","Epoch 48/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7327 - val_loss: 0.3854\n","Epoch 49/50\n","3500/3500 [==============================] - 5s 1ms/step - loss: 0.7326 - val_loss: 0.3862\n","Epoch 50/50\n","3500/3500 [==============================] - 4s 1ms/step - loss: 0.7322 - val_loss: 0.3852\n","(7000, 3)\n"]}]},{"cell_type":"code","source":["print(aeknn_far_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xFJqiwGrroD_","executionInfo":{"status":"ok","timestamp":1688940598283,"user_tz":240,"elapsed":157,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}},"outputId":"c40e2933-d0a0-4984-ad0d-1e7fed89dc17"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["{'acc': 0.983, 'precision': 0.9859154929577465, 'recall': 0.98, 'f1': 0.9829488465396189, 'f2': 0.9811774128954743, 'roc': 0.99824, 'threshold': 0.972}\n"]}]},{"cell_type":"code","source":["aeknn_near_metrics = train_AEKNN(near_X_train, near_X_norm_test, near_X_out_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5EwK98XroJK","executionInfo":{"status":"ok","timestamp":1688940768677,"user_tz":240,"elapsed":170401,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}},"outputId":"4aaaec56-ba7b-4c5e-9bc4-a170931a16b7"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"encoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," encoder_input (InputLayer)  [(None, 19)]              0         \n","                                                                 \n"," encoder_hidden_0 (Dense)    (None, 15)                300       \n","                                                                 \n"," encoder_hidden_1 (Dense)    (None, 7)                 112       \n","                                                                 \n"," z_ (Dense)                  (None, 3)                 24        \n","                                                                 \n","=================================================================\n","Total params: 436\n","Trainable params: 436\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"decoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," z_ (InputLayer)             [(None, 3)]               0         \n","                                                                 \n"," decoder_hidden_0 (Dense)    (None, 7)                 28        \n","                                                                 \n"," decoder_hidden_1 (Dense)    (None, 15)                120       \n","                                                                 \n"," decoder_output (Dense)      (None, 19)                304       \n","                                                                 \n","=================================================================\n","Total params: 452\n","Trainable params: 452\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","2500/2500 [==============================] - 5s 2ms/step - loss: 0.8724 - val_loss: 0.8539\n","Epoch 2/50\n","2500/2500 [==============================] - 4s 2ms/step - loss: 0.7769 - val_loss: 0.8434\n","Epoch 3/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7725 - val_loss: 0.8427\n","Epoch 4/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7716 - val_loss: 0.8413\n","Epoch 5/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7701 - val_loss: 0.8464\n","Epoch 6/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7702 - val_loss: 0.8395\n","Epoch 7/50\n","2500/2500 [==============================] - 4s 1ms/step - loss: 0.7688 - val_loss: 0.8390\n","Epoch 8/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7688 - val_loss: 0.8396\n","Epoch 9/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7678 - val_loss: 0.8389\n","Epoch 10/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7686 - val_loss: 0.8371\n","Epoch 11/50\n","2500/2500 [==============================] - 4s 1ms/step - loss: 0.7673 - val_loss: 0.8367\n","Epoch 12/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7674 - val_loss: 0.8372\n","Epoch 13/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7665 - val_loss: 0.8374\n","Epoch 14/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7664 - val_loss: 0.8362\n","Epoch 15/50\n","2500/2500 [==============================] - 4s 1ms/step - loss: 0.7661 - val_loss: 0.8355\n","Epoch 16/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7663 - val_loss: 0.8359\n","Epoch 17/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7657 - val_loss: 0.8350\n","Epoch 18/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7651 - val_loss: 0.8346\n","Epoch 19/50\n","2500/2500 [==============================] - 4s 1ms/step - loss: 0.7650 - val_loss: 0.8337\n","Epoch 20/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7644 - val_loss: 0.8335\n","Epoch 21/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7644 - val_loss: 0.8333\n","Epoch 22/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7638 - val_loss: 0.8329\n","Epoch 23/50\n","2500/2500 [==============================] - 4s 2ms/step - loss: 0.7639 - val_loss: 0.8374\n","Epoch 24/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7641 - val_loss: 0.8332\n","Epoch 25/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7635 - val_loss: 0.8333\n","Epoch 26/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7636 - val_loss: 0.8324\n","Epoch 27/50\n","2500/2500 [==============================] - 4s 2ms/step - loss: 0.7632 - val_loss: 0.8346\n","Epoch 28/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7634 - val_loss: 0.8333\n","Epoch 29/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7638 - val_loss: 0.8334\n","Epoch 30/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7632 - val_loss: 0.8329\n","Epoch 31/50\n","2500/2500 [==============================] - 4s 2ms/step - loss: 0.7626 - val_loss: 0.8322\n","Epoch 32/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7625 - val_loss: 0.8332\n","Epoch 33/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7625 - val_loss: 0.8335\n","Epoch 34/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7590 - val_loss: 0.8289\n","Epoch 35/50\n","2500/2500 [==============================] - 4s 2ms/step - loss: 0.7577 - val_loss: 0.8273\n","Epoch 36/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7570 - val_loss: 0.8287\n","Epoch 37/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7563 - val_loss: 0.8267\n","Epoch 38/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7564 - val_loss: 0.8273\n","Epoch 39/50\n","2500/2500 [==============================] - 4s 2ms/step - loss: 0.7561 - val_loss: 0.8265\n","Epoch 40/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7558 - val_loss: 0.8260\n","Epoch 41/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7555 - val_loss: 0.8257\n","Epoch 42/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7551 - val_loss: 0.8252\n","Epoch 43/50\n","2500/2500 [==============================] - 4s 2ms/step - loss: 0.7553 - val_loss: 0.8250\n","Epoch 44/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7548 - val_loss: 0.8261\n","Epoch 45/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7549 - val_loss: 0.8243\n","Epoch 46/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7552 - val_loss: 0.8255\n","Epoch 47/50\n","2500/2500 [==============================] - 4s 1ms/step - loss: 0.7545 - val_loss: 0.8247\n","Epoch 48/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7548 - val_loss: 0.8244\n","Epoch 49/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7545 - val_loss: 0.8240\n","Epoch 50/50\n","2500/2500 [==============================] - 3s 1ms/step - loss: 0.7543 - val_loss: 0.8245\n","(5000, 3)\n"]}]},{"cell_type":"code","source":["print(aeknn_near_metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aPYnMzvcroQw","executionInfo":{"status":"ok","timestamp":1688940768679,"user_tz":240,"elapsed":7,"user":{"displayName":"Himanshu Singhal","userId":"05173129179170333528"}},"outputId":"a00c74a3-8c1f-4123-84ab-8ebeb3d41776"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["{'acc': 0.947, 'precision': 0.9339805825242719, 'recall': 0.962, 'f1': 0.9477832512315272, 'f2': 0.956262425447316, 'roc': 0.980928, 'threshold': 1.046}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wWyj5y1vMVUT"},"outputs":[],"source":["def train_seq2seq():\n","    # seq2seq models require a dim 3 input matrix (rows, timesteps, num_features )\n","    in_train_x, in_test_x, out_test_x = np.expand_dims(\n","        in_train, axis=2), np.expand_dims(in_test, axis=2),  np.expand_dims(out_test, axis=2)\n","\n","    seq2seq_kwargs = {}\n","    seq2seq_kwargs[\"encoder_dim\"] = [10]\n","    seq2seq_kwargs[\"decoder_dim\"] = [20]\n","    seq2seq_kwargs[\"epochs\"] = 40\n","    seq2seq_kwargs[\"batch_size\"] = 256\n","    seq2seq_kwargs[\"learning_rate\"] = 0.01\n","    n_features = 1  # single value per feature\n","    seq2seq = Seq2SeqModel(n_features, **seq2seq_kwargs)\n","    seq2seq.train(in_train_x, in_test_x)\n","    seq2seq.save_model()\n","\n","    # seq2seq.load_model()\n","    inlier_scores = seq2seq.compute_anomaly_score(\n","        in_test_x[np.random.randint(100, size=400), :])\n","    outlier_scores = seq2seq.compute_anomaly_score(\n","        out_test_x[np.random.randint(100, size=80), :])\n","\n","    print(inlier_scores[:5])\n","    print(outlier_scores[:5])\n","    metrics = eval_utils.evaluate_model(\n","        inlier_scores, outlier_scores, model_name=\"seq2seq\", show_plot=False)\n","    print(metrics)\n","    return metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RTJZCFFVnvB"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMH06TC3tbNnICMi14lixdy"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}